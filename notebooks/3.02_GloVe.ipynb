{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f6a800; color: #ffffff; padding: 10px;\">\n",
    "<h2>Part 3.2 - Alternative static embeddings: GloVe\n",
    "</div>\n",
    "\n",
    "We are going to review what we did with Word2Vec models but using GloVe Embeddings this time, and we will visualize in 2 dimensions the embeddings.\n",
    "\n",
    "We start with some imports as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nb_config import EXTERNAL_DATA_PATH\n",
    "\n",
    "from src.data import data_loader\n",
    "from src.plotting import visualize_embeddings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>1. Overview\n",
    "</div>\n",
    "\n",
    "**GloVe (Global Vectors for Word Representation)** is an algorithm developed by researchers at Stanford University to generate word embeddings. GloVe operates on the idea that the meaning of words can be inferred from their contexts of use. The algorithm begins by constructing a co-occurrence matrix that represents the frequency of word pairs appearing together within a specified context window. This matrix reflects the statistical information about how often words occur together in the given corpus.\n",
    "\n",
    "The optimization objective of GloVe is to learn vector representations for words in a way that the dot product of two vectors corresponds to the logarithm of the probability of the words' co-occurrence. In other words, GloVe aims to capture the ratios of co-occurrence probabilities between words. The training process involves adjusting the word vectors iteratively to minimize the difference between the dot products of vectors and the logarithm of the observed co-occurrence probabilities.\n",
    "\n",
    "Compared to Word2Vec, which also aims to capture word relationships but does so through a predictive model (either skip-gram or continuous bag of words), GloVe stands out for its emphasis on global context and direct optimization for co-occurrence probabilities. Word2Vec, on the other hand, uses a neural network-based approach to predict words in context, learning embeddings that capture syntactic and semantic relationships.\n",
    "\n",
    "We will make use of **GloVe** pretrained word vectors, specifically the ones that use the Wikipedia 2014 + Gigaword 5 dataset (6B tokens, 400K vocab, uncased, 50d, 100d, 200d, & 300d vectors, 822 MB download).\n",
    "\n",
    "> **NOTE**: If you followed the instructions for preparing this workshop, you should have in the <kbd>data/external</kbd> folder some files called <kbd>glove.6B.XXXd.txt</kbd>. We will work with the 50-dimensional embeddings file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "glove_embeds = {}\n",
    "with open(EXTERNAL_DATA_PATH+'glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0] ## The first entry is the token\n",
    "        coefs = np.asarray(values[1:], dtype='float32') ## The rest is the embedding for that token\n",
    "        glove_embeds[word] = coefs\n",
    "\n",
    "# show how do they look like\n",
    "glove_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the embeddings in two pandas DataFrames, one with the original embeddings as we have read them from our txt file and a second one, with 2-dimensional embeddings created with UMAP for visualization purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings in a DataFrame\n",
    "embeds_df = pd.DataFrame(glove_embeds).T\n",
    "\n",
    "# loads the 2D embeddings of those embeddings\n",
    "umap_df = pd.read_parquet(EXTERNAL_DATA_PATH+'glove_umap_emb.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>2. Related words\n",
    "</div>\n",
    "\n",
    "We will start looking for the closest tokens to a given token. We need first to check if the token is in the vocabulary. We can then calculate the cosine similarity of that token with all the rest of tokens.\n",
    "\n",
    "<div style=\"background-color: #b1063a; color: #ffffff; padding: 10px;\">\n",
    "<strong>Exercise</strong>\n",
    "\n",
    "Choose a word and try to think which other words would you expect to be closer when you plot them. Then take a look to the code to understand what it does. Finally, run the code and see which GloVe embeddings are closer to the word you chose.\n",
    "\n",
    "What can you say about the results?\n",
    "\n",
    "Try with very different words/tokens and see if your observations are consistent with the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the token we want to check\n",
    "word_lookup = \"queen\"\n",
    "\n",
    "# create the emebddings matrix\n",
    "embed_matrix = embeds_df.to_numpy()\n",
    "\n",
    "# get the vector for the lookup token\n",
    "try:\n",
    "    lookup_vector = glove_embeds[word_lookup]\n",
    "    lookup_vector = lookup_vector.reshape((1, -1))\n",
    "except:\n",
    "    print(f\"The token {word_lookup} is not present in the vocabulary.\")\n",
    "\n",
    "# calculate the cosine similarity\n",
    "cos_similarities = cosine_similarity(lookup_vector, embed_matrix).flatten()\n",
    "\n",
    "# put the results in a DataFrame\n",
    "results = pd.DataFrame({'cos_sim':cos_similarities}, index=embeds_df.index)\n",
    "results.loc[:, 'cos_sim'] = cos_similarities\n",
    "\n",
    "# choose number of results\n",
    "n = 5\n",
    "\n",
    "# sort, list and print\n",
    "close_tokens = results.sort_values(by='cos_sim', ascending=False).head(n+1).index.to_list()\n",
    "print(f\"The closest {n} tokens to {close_tokens[0]} are {close_tokens[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the results with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings(close_tokens, umap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>3. Word analogies with GloVe\n",
    "</div>\n",
    "\n",
    "We can also try word analogies as we did for Word2Vec embeddings.\n",
    "\n",
    "<div style=\"background-color: #b1063a; color: #ffffff; padding: 10px;\">\n",
    "<strong>Exercise</strong>\n",
    "\n",
    "Take a look to the code to understand what it does. Choose some different word analogies like:\n",
    "- *Which word is to woman, what king is to man?*\n",
    "- *Which word is to France, what Berlin is to Germany?*\n",
    "\n",
    "Run the code and see which tokens are closer to the vector of your word analogy.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the tokens for word analogy\n",
    "base_token = \"king\"\n",
    "negative_token = \"man\"\n",
    "positive_token = \"woman\"\n",
    "\n",
    "# number of closest tokens we want to show\n",
    "n = 5\n",
    "\n",
    "# create the lookup vector\n",
    "try:\n",
    "    lookup_vector = glove_embeds[base_token] - glove_embeds[negative_token] + glove_embeds[positive_token]\n",
    "    lookup_vector = lookup_vector.reshape([1, -1])\n",
    "except:\n",
    "    print(f\"One of the tokens is not present in the vocabulary.\")\n",
    "\n",
    "# calculate cosine similarity\n",
    "cos_similarities = cosine_similarity(lookup_vector, embed_matrix).flatten()\n",
    "\n",
    "# put results in a DataFrame\n",
    "results = pd.DataFrame({'cos_sim':cos_similarities}, index=embeds_df.index)\n",
    "results.loc[:, 'cos_sim'] = cos_similarities\n",
    "\n",
    "# list the closest n tokens\n",
    "close_tokens = results.sort_values(by='cos_sim', ascending=False).head(n).index.to_list()\n",
    "print(f\"The closest {n} tokens are {close_tokens}\")\n",
    "\n",
    "# select query vectors in 2D from list of closest tokens\n",
    "lookup_umap = (umap_df.loc[base_token].values - umap_df.loc[negative_token].values + umap_df.loc[positive_token].values).reshape([1, -1])\n",
    "\n",
    "# visualize the query and the closest tokens\n",
    "visualize_embeddings(close_tokens, umap_df, lookup_umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is something strange going on with our word analogies...\n",
    "\n",
    "Did you get what you were expecting? Did the results surprise you?\n",
    "\n",
    "<div style=\"background-color: #b1063a; color: #ffffff; padding: 10px;\">\n",
    "<strong>Exercise</strong>\n",
    "\n",
    "What happened with the countries and their capitals? Why didn't it work?\n",
    "\n",
    "Formulate a hypothesis that justifies this anomaly. Discuss your hypothesis with other participants.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Let's focus now on the first analogy. What happened?\n",
    "\n",
    "<div style=\"background-color: #b1063a; color: #ffffff; padding: 10px;\">\n",
    "<strong>Exercise</strong>\n",
    "\n",
    "Try other word analogies like:\n",
    "- *king - son + daughter = ?*\n",
    "- *father - uncle + aunt = ?*\n",
    "\n",
    "Which analogies worked well?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try to shed some light on the problem, let us visualize some related tokens that we would expect to behave in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_words = ['man', 'woman', 'queen', 'king', 'father', 'mother', 'son', 'daughter']\n",
    "\n",
    "visualize_embeddings(analogy_words, umap_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now where is the problem. All pairs (*father-mother*, *son-daughter*, *king-queen*) show in a very general way the same direction, downwards to the right from the male to the female counterpart. However, the *man-woman* pair goes in the opposite direction, upwards to the left. What do you think could be the reason for this?\n",
    "\n",
    "<div style=\"background-color: #b1063a; color: #ffffff; padding: 10px;\">\n",
    "<strong>Exercise</strong>\n",
    "\n",
    "Formulate a hypothesis that justifies this anomaly. Discuss your hypothesis with other participants.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>4. Queries with GloVe\n",
    "</div>\n",
    "\n",
    "But now we want to check again our use case. How does this model performs?\n",
    "\n",
    "We need to retrieve again our tokenized descriptors. But we know already how does it work. And as with Word2Vec we are going to create descriptor embeddings by averaging the vectors for all the tokens in the descriptor.\n",
    "\n",
    "> **NOTE**: We have seen that with this model some ways of tokenizing could be better than others. So this could be perhaps a good moment for going back and creating new tokens with a different configuration, if you think that that would improve the semantic search engine.\n",
    "\n",
    "We load and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, params = data_loader(\"my_tokenized_data.parquet\")\n",
    "\n",
    "# extract the arguments for the normalize function\n",
    "tokenizer = params['tokenizer']\n",
    "arguments = params['args']\n",
    "\n",
    "# print the tokenizer used getting the tokens\n",
    "print(f\"Tokenizer used: {tokenizer}\")\n",
    "print(f\"Arguments passed to the normalize function:\\n{arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the corpus matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a Pandas series with the averaged vectors\n",
    "corpus_matrix = df.loc[:, 'tokens'].map(lambda x: np.sum([glove_embeds[token] for token in x if token in glove_embeds.keys()], axis=0))\n",
    "# creates the matrix from the vectors\n",
    "corpus_matrix = np.vstack(corpus_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's turn to tokenize the query and create its embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"An innocent man goes to prison accused of killing his wife and her lover, but never loses the hope\"\n",
    "\n",
    "from src.normalizing import normalize, NLTKTokenizer\n",
    "\n",
    "# instantiate the tokenizer\n",
    "tkn = NLTKTokenizer()\n",
    "\n",
    "# tokenize the query with the same tokenizer you used for the corpus texts\n",
    "query_tokens = normalize(query, tkn, punct_signs=True)[1]\n",
    "\n",
    "query_vector = np.sum([glove_embeds[token] for token in query_tokens if token in glove_embeds.keys()], axis=0)\n",
    "query_vector = query_vector.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as usual, we compare the query with the descriptors in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the distances\n",
    "euclid_distances = euclid_dist_AB = np.linalg.norm(corpus_matrix - query_vector, axis=1)\n",
    "dotprod_similarities = np.dot(corpus_matrix, query_vector.T)\n",
    "cos_similarities = cosine_similarity(query_vector, corpus_matrix).flatten()\n",
    "\n",
    "# creating the new dataframe and adding the extra columns\n",
    "results = df.loc[:, ['title', 'descriptor']].copy()\n",
    "results.loc[:, 'euclid_dist'] = euclid_distances\n",
    "results.loc[:, 'dot_prod_sim'] = dotprod_similarities\n",
    "results.loc[:, 'cos_sim'] = cos_similarities\n",
    "results.loc[:, 'common_tokens'] = df.loc[:, 'tokens'].map(lambda x: list(set(x).intersection(query_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric! options:\n",
    "# 'euclid_dist', 'dot_prod_sim', 'cos_sim'\n",
    "metric = 'cos_sim'\n",
    "\n",
    "# choose number of results\n",
    "n = 10\n",
    "\n",
    "# show the results\n",
    "# ascending=False for 'dot_prod_sim' and 'cos_sim'\n",
    "# ascending=FTrue for 'euclid_dist'\n",
    "results.sort_values(by=metric, ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #b1063a; color: #ffffff; padding: 10px;\">\n",
    "<strong>Exercise</strong>\n",
    "\n",
    "How was the result? Try several queries with different complexity levels and try to understand when works better and when worse.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>5. Advantages and disadvantages of GloVe\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages:\n",
    "\n",
    "> - **Semantic Precision**: GloVe excels in capturing intricate semantic relationships based on global co-occurrence patterns. This precision provides a nuanced understanding of word meanings, surpassing some other embedding methods.\n",
    ">  - **Reduced Sensitivity to Noise**: GloVe demonstrates resilience to noise and outliers in training data. This robustness contributes to stable embeddings, making them reliable in the presence of varied and noisy textual data.\n",
    "> - **Pre-trained Embeddings Availability**: Pre-trained GloVe embeddings are widely accessible for multiple languages and domains. This availability facilitates transfer learning, allowing users to leverage pre-trained embeddings in downstream tasks with limited data.\n",
    "\n",
    "#### Disadvantages:\n",
    "\n",
    "> - **Fixed Vocabulary Size**: GloVe operates with a fixed vocabulary size determined during training. This fixed nature may limit adaptation, particularly in scenarios where language usage evolves over time.\n",
    "> - **Limited Representation of Polysemy**: GloVe may struggle with polysemy, as it assigns a single vector to each word. This limitation poses challenges in effectively representing words with multiple meanings.\n",
    "> - **Dependency on Training Data Quality**: The quality of GloVe embeddings heavily relies on the diversity and representativeness of the training corpus. Biased or unrepresentative training data may result in suboptimal embeddings.\n",
    "\n",
    "#### Applications:\n",
    "\n",
    "> - **Review Sentiment Classification**: Leveraging GloVe embeddings for sentiment analysis enhances the accuracy of classifying sentiments in product or service reviews, enabling more precise identification of positive and negative sentiments.\n",
    ">  - **Document Clustering for Topic Discovery**: Applying GloVe embeddings in document clustering facilitates the discovery of topics within a large corpus, grouping similar documents based on the semantic relationships between words.\n",
    "> - **Named Entity Recognition (NER) in Text**: Integrating GloVe embeddings into Named Entity Recognition tasks improves the identification and classification of named entities within textual data, aiding in information extraction.\n",
    "> - **Keyword Extraction from Scientific Papers**: Utilizing GloVe embeddings for keyword extraction in scientific papers enhances the identification of critical terms, providing a more refined summary and categorization of research content.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
